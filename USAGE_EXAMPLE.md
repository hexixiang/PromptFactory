# 使用示例

## 快速开始

### 1. 启动应用
```bash
python app.py
```
应用将在 `http://localhost:5001` 启动

### 2. 创建项目
1. 打开浏览器访问 `http://localhost:5001`
2. 点击"创建新项目"
3. 填写以下信息：
   ```
   项目名称: 测试项目
   API地址: https://api.openai.com/v1/chat/completions
   模型名称: gpt-4
   API密钥: sk-your-api-key-here
   温度: 0.7
   最大生成长度: 1000
   超时时间: 30
   频率限制: 5
   ```

### 3. 测试API连接
1. 在项目详情页面点击"开始新处理"
2. 上传 `test_data.jsonl` 文件
3. 编写提示词模板：
   ```
   请根据以下信息生成回复：
   
   用户输入：{{user_input}}
   
   请提供有帮助的回答。
   ```
4. 点击"测试提示词"按钮

### 4. 批量处理
1. 设置并发工作线程数（建议5-10）
2. 点击"开始处理"
3. 等待处理完成
4. 下载结果文件

## 示例数据

`test_data.jsonl` 文件内容：
```json
{"text": "你好，请介绍一下人工智能", "user_input": "什么是AI"}
{"text": "请解释机器学习的基本概念", "user_input": "机器学习是什么"}
{"text": "深度学习与传统机器学习的区别", "user_input": "深度学习和机器学习的区别"}
```

## 提示词模板示例

### 基础模板
```
请回答以下问题：{{user_input}}
```

### 详细模板
```
请根据以下信息生成回复：

用户问题：{{user_input}}
原始文本：{{text}}

请提供详细、准确的回答。
```

### 翻译模板
```
请将以下文本翻译成英文：

原文：{{text}}

请提供准确的英文翻译。
```

## 常见配置

### OpenAI API
- **API地址**: `https://api.openai.com/v1/chat/completions`
- **模型名称**: `gpt-4`, `gpt-3.5-turbo`
- **温度**: 0.7 (创造性) 或 0.3 (准确性)
- **最大生成长度**: 1000-4000

### 其他API
- **API地址**: 根据具体API提供商
- **认证方式**: 根据API要求设置

## 故障排除

### 1. API调用失败
- 检查API密钥是否正确
- 确认API地址和模型名称
- 查看网络连接

### 2. 文件上传失败
- 确保文件格式为JSONL
- 检查JSON格式是否正确
- 确认文件编码为UTF-8

### 3. 处理速度慢
- 减少并发数
- 检查API限制
- 优化提示词长度

## 高级功能

### 1. 自定义变量
在JSONL文件中可以包含任意字段，在提示词中使用 `{{字段名}}` 引用

### 2. 批量处理
支持大量数据批量处理，自动处理错误和重试

### 3. 处理历史
查看历史处理记录，包括成功率和错误统计

### 4. 结果下载
处理完成后自动生成JSONL格式的结果文件 